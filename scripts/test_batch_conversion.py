#!/usr/bin/env python3
"""
æµ‹è¯•æ‰¹é‡è½¬æ¢åŠŸèƒ½çš„æ¼”ç¤ºè„šæœ¬
"""
import logging
import sys
import time
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from protein_tensor import convert_structures, BatchConverter

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_test_structure():
    """åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„ã€‚"""
    test_dir = Path("test_structures")
    test_dir.mkdir(exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•ç»“æ„
    (test_dir / "proteins").mkdir(exist_ok=True)
    (test_dir / "ligands").mkdir(exist_ok=True)
    
    # å¤åˆ¶æµ‹è¯•æ–‡ä»¶åˆ°ä¸åŒä½ç½®
    import shutil
    
    # æ ¹ç›®å½•çš„æ–‡ä»¶
    if Path("9kvc.pdb").exists():
        shutil.copy("9kvc.pdb", test_dir / "protein_1.pdb")
    if Path("9kvc.cif").exists():
        shutil.copy("9kvc.cif", test_dir / "protein_1.cif")
    
    # å­ç›®å½•çš„æ–‡ä»¶
    if Path("9kvc.pdb").exists():
        shutil.copy("9kvc.pdb", test_dir / "proteins" / "complex.pdb")
    if Path("9kvc.cif").exists():
        shutil.copy("9kvc.cif", test_dir / "ligands" / "small_molecule.cif")
    
    logger.info(f"åˆ›å»ºæµ‹è¯•ç›®å½•ç»“æ„: {test_dir}")
    return test_dir


def test_single_file_conversion():
    """æµ‹è¯•å•æ–‡ä»¶è½¬æ¢ã€‚"""
    logger.info("ğŸ§ª æµ‹è¯• 1: å•æ–‡ä»¶è½¬æ¢")
    
    pdb_file = Path("9kvc.pdb")
    if not pdb_file.exists():
        logger.warning("PDBæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡å•æ–‡ä»¶æµ‹è¯•")
        return
    
    output_dir = Path("single_conversion_output")
    
    start_time = time.time()
    results = convert_structures(
        input_path=pdb_file,
        output_dir=output_dir,
        backend="numpy",
        n_workers=1
    )
    elapsed_time = time.time() - start_time
    
    logger.info(f"å•æ–‡ä»¶è½¬æ¢ç»“æœ: {results}")
    logger.info(f"è½¬æ¢è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    # éªŒè¯è¾“å‡ºæ–‡ä»¶
    output_files = list(output_dir.glob("*.npz"))
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {[f.name for f in output_files]}")


def test_batch_conversion_numpy():
    """æµ‹è¯•æ‰¹é‡è½¬æ¢ (numpyåç«¯)ã€‚"""
    logger.info("ğŸ§ª æµ‹è¯• 2: æ‰¹é‡è½¬æ¢ (numpyåç«¯)")
    
    test_dir = create_test_structure()
    output_dir = Path("batch_numpy_output")
    
    start_time = time.time()
    results = convert_structures(
        input_path=test_dir,
        output_dir=output_dir,
        backend="numpy",
        recursive=True,
        preserve_structure=True,
        n_workers=2
    )
    elapsed_time = time.time() - start_time
    
    logger.info(f"numpyæ‰¹é‡è½¬æ¢ç»“æœ: {results}")
    logger.info(f"è½¬æ¢è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    # æ˜¾ç¤ºè¾“å‡ºç»“æ„
    logger.info("è¾“å‡ºæ–‡ä»¶ç»“æ„:")
    for file in sorted(output_dir.rglob("*")):
        if file.is_file():
            logger.info(f"  {file.relative_to(output_dir)}")


def test_batch_conversion_torch():
    """æµ‹è¯•æ‰¹é‡è½¬æ¢ (torchåç«¯)ã€‚"""
    logger.info("ğŸ§ª æµ‹è¯• 3: æ‰¹é‡è½¬æ¢ (torchåç«¯)")
    
    test_dir = Path("test_structures")
    if not test_dir.exists():
        logger.warning("æµ‹è¯•ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡torchæ‰¹é‡æµ‹è¯•")
        return
    
    output_dir = Path("batch_torch_output")
    
    start_time = time.time()
    results = convert_structures(
        input_path=test_dir,
        output_dir=output_dir,
        backend="torch",
        recursive=True,
        preserve_structure=False,  # å¹³é“ºè¾“å‡º
        n_workers=1
    )
    elapsed_time = time.time() - start_time
    
    logger.info(f"torchæ‰¹é‡è½¬æ¢ç»“æœ: {results}")
    logger.info(f"è½¬æ¢è€—æ—¶: {elapsed_time:.2f} ç§’")
    
    # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶
    output_files = list(output_dir.glob("*.pt"))
    logger.info(f"è¾“å‡ºæ–‡ä»¶: {[f.name for f in output_files]}")


def test_load_converted_data():
    """æµ‹è¯•åŠ è½½è½¬æ¢åçš„æ•°æ®ã€‚"""
    logger.info("ğŸ§ª æµ‹è¯• 4: åŠ è½½è½¬æ¢åçš„æ•°æ®")
    
    # æµ‹è¯•åŠ è½½numpyæ•°æ®
    numpy_dir = Path("batch_numpy_output")
    if numpy_dir.exists():
        numpy_files = list(numpy_dir.rglob("*.npz"))
        if numpy_files:
            import numpy as np
            data = np.load(numpy_files[0], allow_pickle=True)
            logger.info(f"numpyæ•°æ®æ–‡ä»¶: {numpy_files[0]}")
            logger.info(f"  åŒ…å«çš„é”®: {list(data.keys())}")
            logger.info(f"  åæ ‡å½¢çŠ¶: {data['coordinates'].shape}")
            logger.info(f"  å…ƒæ•°æ®: {data['metadata'].item()}")
    
    # æµ‹è¯•åŠ è½½torchæ•°æ®
    torch_dir = Path("batch_torch_output")
    if torch_dir.exists():
        torch_files = list(torch_dir.glob("*.pt"))
        if torch_files:
            try:
                import torch
                data = torch.load(torch_files[0])
                logger.info(f"torchæ•°æ®æ–‡ä»¶: {torch_files[0]}")
                logger.info(f"  åŒ…å«çš„é”®: {list(data.keys())}")
                logger.info(f"  åæ ‡å½¢çŠ¶: {data['coordinates'].shape}")
                logger.info(f"  å…ƒæ•°æ®: {data['metadata']}")
            except ImportError:
                logger.warning("PyTorchæœªå®‰è£…ï¼Œè·³è¿‡torchæ•°æ®åŠ è½½æµ‹è¯•")


def test_converter_class():
    """æµ‹è¯•BatchConverterç±»çš„ç›´æ¥ä½¿ç”¨ã€‚"""
    logger.info("ğŸ§ª æµ‹è¯• 5: BatchConverterç±»ç›´æ¥ä½¿ç”¨")
    
    # åˆ›å»ºè½¬æ¢å™¨å®ä¾‹
    converter = BatchConverter(
        backend="numpy",
        n_workers=1,
        preserve_structure=True
    )
    
    # æµ‹è¯•å•æ–‡ä»¶è½¬æ¢
    pdb_file = Path("9kvc.pdb")
    if pdb_file.exists():
        output_file = Path("class_test_output") / "test.npz"
        success = converter.convert_single(pdb_file, output_file)
        logger.info(f"BatchConverterå•æ–‡ä»¶è½¬æ¢: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        if success and output_file.exists():
            import numpy as np
            data = np.load(output_file, allow_pickle=True)
            logger.info(f"  æ–‡ä»¶å¤§å°: {output_file.stat().st_size // 1024} KB")
            logger.info(f"  åŸå­æ•°é‡: {data['metadata'].item()['n_atoms']}")


def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶ã€‚"""
    logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶")
    
    import shutil
    cleanup_dirs = [
        "test_structures",
        "single_conversion_output", 
        "batch_numpy_output",
        "batch_torch_output",
        "class_test_output"
    ]
    
    for dir_name in cleanup_dirs:
        dir_path = Path(dir_name)
        if dir_path.exists():
            shutil.rmtree(dir_path)
            logger.info(f"åˆ é™¤ç›®å½•: {dir_path}")


def main():
    """ä¸»å‡½æ•°ï¼Œè¿è¡Œæ‰€æœ‰æµ‹è¯•ã€‚"""
    logger.info("ğŸš€ å¼€å§‹æ‰¹é‡è½¬æ¢åŠŸèƒ½æµ‹è¯•")
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_single_file_conversion()
        print()
        
        test_batch_conversion_numpy()
        print()
        
        test_batch_conversion_torch()
        print()
        
        test_load_converted_data()
        print()
        
        test_converter_class()
        print()
        
        logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶
        response = input("\næ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶? (y/N): ").strip().lower()
        if response in ['y', 'yes']:
            cleanup_test_files()
        else:
            logger.info("ä¿ç•™æµ‹è¯•æ–‡ä»¶ä¾›æŸ¥çœ‹")
        
    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 